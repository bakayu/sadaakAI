{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.9.2\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.7.0\n",
      "torch version: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"matplotlib\",\n",
    "    \"numpy\",\n",
    "    \"tiktoken\",\n",
    "    \"torch\",\n",
    "]\n",
    "\n",
    "for _ in pkgs:\n",
    "    print(f\"{_} version: {version(_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Using GPT to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from supplementary import GPTModel\n",
    "\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from supplementary import generate_text_simple\n",
    "\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Preparing the dataset loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/the-verdict.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# First 100 characters\n",
    "print(text_data[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "# Last 100 characters\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supplementary import create_dataloader_v1\n",
    "\n",
    "\n",
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583796183268\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "from supplementary import calc_loss_loader\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Training the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supplementary import (\n",
    "    calc_loss_batch,\n",
    "    evaluate_model,\n",
    "    generate_and_print_sample\n",
    ")\n",
    "\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.825, Val loss 9.931\n",
      "Ep 1 (Step 000005): Train loss 8.069, Val loss 8.341\n",
      "Every effort moves you,,,,,,,,,,,,,,.                                   \n",
      "Ep 2 (Step 000010): Train loss 6.625, Val loss 7.051\n",
      "Ep 2 (Step 000015): Train loss 6.048, Val loss 6.599\n",
      "Every effort moves you, and,, and,,,,,,,,,.                                   \n",
      "Ep 3 (Step 000020): Train loss 5.574, Val loss 6.494\n",
      "Ep 3 (Step 000025): Train loss 5.504, Val loss 6.413\n",
      "Every effort moves you, and, and, and, and, and, and, and of the of the of the of the to to to the to to the of the of the of the of the of the's, and, and, and, and, and\n",
      "Ep 4 (Step 000030): Train loss 5.078, Val loss 6.322\n",
      "Ep 4 (Step 000035): Train loss 4.836, Val loss 6.315\n",
      "Every effort moves you a the picture. I had been the picture-- the picture. Gisburn. I had been, and the of the of the of the the of the of the picture. I had the of the of the of the of the of the of\n",
      "Ep 5 (Step 000040): Train loss 4.222, Val loss 6.178\n",
      "Every effort moves you know the fact of the \"--I looked--and a little of the house-hum--and it's     \"I said--as Jack himself at the donkey.           \n",
      "Ep 6 (Step 000045): Train loss 3.843, Val loss 6.124\n",
      "Ep 6 (Step 000050): Train loss 3.297, Val loss 6.142\n",
      "Every effort moves you know the \"Oh, and in the \"I had the last word.           \"Oh, and I had a little the donkey. \"I, and down, and he was his\n",
      "Ep 7 (Step 000055): Train loss 3.274, Val loss 6.216\n",
      "Ep 7 (Step 000060): Train loss 2.529, Val loss 6.135\n",
      "Every effort moves you know the picture to have been too? I felt, and I felt him--so it was no I felt to me to have to see a smile behind his pictures that he had not till his painting, I had been--because he had the his\n",
      "Ep 8 (Step 000065): Train loss 2.047, Val loss 6.161\n",
      "Ep 8 (Step 000070): Train loss 1.717, Val loss 6.240\n",
      "Every effort moves you know,\" was one of the picture. Gisburn--as such--had not to my work, and!     \"Oh, and I had been the donkey--and I had the donkey. \"There were days when I\n",
      "Ep 9 (Step 000075): Train loss 1.349, Val loss 6.227\n",
      "Ep 9 (Step 000080): Train loss 1.034, Val loss 6.278\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on that I felt to have given Miss Croft the fact, and that, in the moment--as Jack himself, his pictures--the quality of Jack's \"strongest,\" she was\n",
      "Ep 10 (Step 000085): Train loss 0.773, Val loss 6.372\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from supplementary import plot_losses\n",
    "\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generating text from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m tiktoken\u001b[38;5;241m.\u001b[39mget_encoding(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_text_simple\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_to_token_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGPT_CONFIG_124M\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/work/sadaak_htm/sadaakAI/model/03_pretraining/supplementary.py:297\u001b[0m, in \u001b[0;36mgenerate_text_simple\u001b[0;34m(model, idx, max_new_tokens, context_size)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# Get the predictions\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 297\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx_cond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Focus only on the last time step\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
      "File \u001b[0;32m~/.conda/envs/llms/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/llms/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/work/sadaak_htm/sadaakAI/model/03_pretraining/supplementary.py:195\u001b[0m, in \u001b[0;36mGPTModel.forward\u001b[0;34m(self, in_idx)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, in_idx):\n\u001b[1;32m    194\u001b[0m     batch_size, seq_len \u001b[38;5;241m=\u001b[39m in_idx\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 195\u001b[0m     tok_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtok_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m     pos_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_emb(torch\u001b[38;5;241m.\u001b[39marange(seq_len, device\u001b[38;5;241m=\u001b[39min_idx\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[1;32m    197\u001b[0m     x \u001b[38;5;241m=\u001b[39m tok_embeds \u001b[38;5;241m+\u001b[39m pos_embeds  \u001b[38;5;66;03m# Shape [batch_size, num_tokens, emb_size]\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/llms/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/llms/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/llms/lib/python3.10/site-packages/torch/nn/modules/sparse.py:164\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/llms/lib/python3.10/site-packages/torch/nn/functional.py:2267\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2261\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2264\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2265\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2266\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer).to(device),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_457958/1083122488.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from supplementary import GPTModel\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
